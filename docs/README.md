# TempSAL - Uncovering Temporal Information for Deep Saliency Prediction

![teaser-updated](https://user-images.githubusercontent.com/16324609/211349283-4cd56e79-80c9-4c5e-8181-f5c73b649870.png)
An example of how human attention evolves over time. Top row: \textbf{\textcolor{orange}{Temporal}} and \textbf{\textcolor{mypink}{image}} saliency ground truth from the SALICON dataset~\cite{salicon}. Bottom row: Our \textbf{\textcolor{myorange}{temporal}} and \textbf{\textcolor{mypink}{image}}  saliency predictions. Each temporal saliency map $\mathcal{T}_i$, $i \in \{1,\ldots,5\}$ represents one second of observation time. Note that in $\mathcal{T}_1$, the chef is salient, while in  $\mathcal{T}_2$ and  $\mathcal{T}_3$, the food on the barbecue becomes the most salient region in this scene. We can predict the temporal saliency maps for each interval separately, or combine them to create a single, refined image saliency map for the entire observation period.  



We will relase the code on this repository upon publication.

Paper link : https://arxiv.org/abs/2301.02315

Project page and Supplementary material : https://baharay.github.io/tempsal/



# Website License
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
